{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TNG_DA\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS+ and Virial Theorem plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = 3\n",
    "\n",
    "pos, vel, groups, subhalo_masses, h, halo_mass = TNG_DA.get_cluster_props(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = \"/home/habjan.e/TNG/Data/data_DS+_virial_results/DS+_Virial_df.csv\"\n",
    "df = pd.read_csv(df_path)\n",
    "\n",
    "subhalo_masses = np.load('/home/habjan.e/TNG/Data/data_DS+_virial_results/subhalo_masses.npy')\n",
    "dsp_out_1 = np.load('/home/habjan.e/TNG/Data/data_DS+_virial_results/DS+_array_1.npy')\n",
    "dsp_out_2 = np.load('/home/habjan.e/TNG/Data/data_DS+_virial_results/DS+_array_2.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make array of projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_proj = np.array(df['Projection x-Direction'])\n",
    "y_proj = np.array(df['Projection y-Direction'])\n",
    "z_proj = np.array(df['Projection z-Direction'])\n",
    "\n",
    "df_proj_arr = np.transpose(np.array([x_proj, y_proj, z_proj]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a histogram of the Virial mass estimates of the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "virial_cluster_mass = np.array(df['Virial Halo Mass'])\n",
    "\n",
    "bins = np.linspace(np.nanmin(virial_cluster_mass), np.nanmax(virial_cluster_mass), 50)\n",
    "\n",
    "plt.hist(virial_cluster_mass, color='blue', bins=bins);\n",
    "plt.axvline(halo_mass, c='k', linestyle='--', label='TNG Cluster Mass')\n",
    "\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel(r'Virial Theorem Mass [$M_{\\odot}$]')\n",
    "\n",
    "#plt.yscale('log')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare position distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(np.nanmin(pos), np.nanmax(pos), 50)\n",
    "\n",
    "plt.hist(pos[:, 1], color='red', bins=bins);\n",
    "plt.hist(pos[:, 2], color='green', bins=bins);\n",
    "plt.hist(pos[:, 0], color='blue', bins=bins);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantifying Trixiality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_results = np.transpose(np.array([TNG_DA.compare_3d_2d_shape(pos, vel, df_proj_arr[i]) for i in range(len(df))]))\n",
    "\n",
    "shape_3d = tri_results[0]\n",
    "shape_2d = tri_results[1]\n",
    "tri_metric_arr = tri_results[2]\n",
    "T = tri_results[3, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate differences in true 3D velocity dispersion and assumed los velocity dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_disp_x = np.sum((vel[:, 0] - np.mean(vel[:, 0]))**2) / len(vel[:, 0])\n",
    "true_disp_y = np.sum((vel[:, 1] - np.mean(vel[:, 1]))**2) / len(vel[:, 1])\n",
    "true_disp_z = np.sum((vel[:, 2] - np.mean(vel[:, 2]))**2) / len(vel[:, 2])\n",
    "true_vel_disp = np.sqrt(true_disp_x + true_disp_y + true_disp_z)\n",
    "\n",
    "los_velocities = np.array([TNG_DA.project_3d_to_2d(pos, vel, df_proj_arr[i])[1] for i in range(df_proj_arr.shape[0])])\n",
    "vel_los_disp = np.array([np.sqrt((1 / (len(los_velocities[i]) - 1)) * np.sum((los_velocities[i] - np.mean(los_velocities[i]))**2)) for i in range(los_velocities.shape[0])]) * np.sqrt(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot mass difference versus the triaxiality metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vel_disp_diff = true_vel_disp - vel_los_disp\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "sc = plt.scatter(tri_metric_arr, virial_cluster_mass, c=vel_disp_diff, cmap='viridis')\n",
    "plt.axhline(halo_mass, c='k', linestyle='--', label=r'TNG Halo Mass [$M_{\\odot}$]')\n",
    "\n",
    "cbar = plt.colorbar(sc)\n",
    "cbar.set_label(r'$\\sigma_{true} - \\sigma_{los}$ [$km s^{-1}$]', fontsize = 15)\n",
    "\n",
    "plt.xlabel(r'$ \\mathcal{S}_{2D} - \\mathcal{S}_{3D}$', fontsize = 15)\n",
    "plt.ylabel(r'Virial Theorem Mass [$M_{\\odot}$]', fontsize = 15)\n",
    "plt.legend()\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tri_metric_arr\n",
    "y = np.log10(virial_cluster_mass)\n",
    "\n",
    "num_bins = 20 \n",
    "bins = np.linspace(min(x), max(x), num_bins + 1)\n",
    "bin_indices = np.digitize(x, bins) - 1\n",
    "\n",
    "# Compute statistics per bin (mean, median, etc.)\n",
    "bin_means = np.array([np.mean(y[bin_indices == i]) if np.any(bin_indices == i) else np.nan for i in range(num_bins)])\n",
    "bin_std = np.array([np.std(y[bin_indices == i]) if np.any(bin_indices == i) else np.nan for i in range(num_bins)])\n",
    "bin_centers = (bins[:-1] + bins[1:]) / 2  # Compute bin centers\n",
    "\n",
    "# Plot original data as scatter\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(x, y, s=5, c ='k', alpha = 0.3)\n",
    "\n",
    "# Plot binned means as points or line\n",
    "plt.plot(bin_centers, bin_means, 'ro-', markersize=8)\n",
    "plt.fill_between(bin_centers, bin_means - bin_std, bin_means + bin_std, color='red', alpha=0.2)\n",
    "\n",
    "plt.xlabel(r'$ \\mathcal{S}_{2D} - \\mathcal{S}_{3D}$', fontsize = 15)\n",
    "plt.ylabel(r'Virial Theorem Mass [$log_{10}(M_{\\odot})$]', fontsize = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete = np.array(df['Completeness'])\n",
    "complete_err = np.array(df['Completeness Uncertainty'])\n",
    "\n",
    "x = tri_metric_arr\n",
    "y = complete\n",
    "\n",
    "num_bins = 20 \n",
    "bins = np.linspace(min(x), max(x), num_bins + 1)\n",
    "bin_indices = np.digitize(x, bins) - 1\n",
    "\n",
    "# Compute statistics per bin (mean, median, etc.)\n",
    "bin_means = np.array([np.mean(y[bin_indices == i]) if np.any(bin_indices == i) else np.nan for i in range(num_bins)])\n",
    "bin_std = np.array([np.std(y[bin_indices == i]) if np.any(bin_indices == i) else np.nan for i in range(num_bins)])\n",
    "bin_centers = (bins[:-1] + bins[1:]) / 2  # Compute bin centers\n",
    "\n",
    "# Plot original data as scatter\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(x, y, s=5, c ='k', alpha = 0.3)\n",
    "\n",
    "# Plot binned means as points or line\n",
    "plt.plot(bin_centers, bin_means, 'ro-', markersize=8)\n",
    "plt.fill_between(bin_centers, bin_means - bin_std, bin_means + bin_std, color='red', alpha=0.3)\n",
    "\n",
    "plt.xlabel(r'$ \\mathcal{S}_{2D} - \\mathcal{S}_{3D}$', fontsize = 15)\n",
    "plt.ylabel('Completeness', fontsize = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purity = np.array(df['Purity'])\n",
    "purity_err = np.array(df['Purity Uncertainty'])\n",
    "\n",
    "x = tri_metric_arr\n",
    "y = purity\n",
    "\n",
    "num_bins = 20 \n",
    "bins = np.linspace(min(x), max(x), num_bins + 1)\n",
    "bin_indices = np.digitize(x, bins) - 1\n",
    "\n",
    "# Compute statistics per bin (mean, median, etc.)\n",
    "bin_means = np.array([np.mean(y[bin_indices == i]) if np.any(bin_indices == i) else np.nan for i in range(num_bins)])\n",
    "bin_std = np.array([np.std(y[bin_indices == i]) if np.any(bin_indices == i) else np.nan for i in range(num_bins)])\n",
    "bin_centers = (bins[:-1] + bins[1:]) / 2  # Compute bin centers\n",
    "\n",
    "# Plot original data as scatter\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(x, y, s=5, c ='k', alpha = 0.3)\n",
    "\n",
    "# Plot binned means as points or line\n",
    "plt.plot(bin_centers, bin_means, 'ro-', markersize=8)\n",
    "plt.fill_between(bin_centers, bin_means - bin_std, bin_means + bin_std, color='red', alpha=0.3)\n",
    "\n",
    "plt.xlabel(r'$ \\mathcal{S}_{2D} - \\mathcal{S}_{3D}$', fontsize = 15)\n",
    "plt.ylabel('Purity', fontsize = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
